{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå¥ Asistente Tur√≠stico de Tenerife - RAG Demo\n",
    "\n",
    "## 1. Configuraci√≥n del Entorno\n",
    "Cargamos las librer√≠as necesarias y verificamos la API Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Key cargada: sk-pr...\n",
      "‚úÖ Clientes OpenAI inicializados.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import nest_asyncio\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    print(f\"‚úÖ Key cargada: {api_key[:5]}...\")\n",
    "else:\n",
    "    print(\"‚ùå Error de Key\")\n",
    "\n",
    "# Aplicar nest_asyncio para Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Inicializar Clientes (Sync para utilidades, Async para Agentes)\n",
    "client = OpenAI(api_key=api_key)\n",
    "aclient = AsyncOpenAI(api_key=api_key)\n",
    "print(\"‚úÖ Clientes OpenAI inicializados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validaci√≥n de Conectividad con OpenAI\n",
    "Probamos que la llave funcione y el modelo responda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Respuesta Modelo: Hola Tenerife. ¬øEn qu√© puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Inicializamos el modelo\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Prueba 'Hol√≠stica'\n",
    "try:\n",
    "    response = llm.invoke(\"Di 'Hola Tenerife' si me escuchas.\")\n",
    "    print(f\"ü§ñ Respuesta Modelo: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error de Conexi√≥n: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fase 2: Ingesta y Vector Store üìö\n",
    "Subimos el PDF `TENERIFE.pdf` a OpenAI para crear un Vector Store gestionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF: ..\\data\\raw\\TENERIFE.pdf\n",
      "[CACH√â] ‚ö° ID recuperado y verificado: vs_69679a01bdec8191a9eec55d1cae9f08\n",
      "‚úÖ Fase 2 Lista. ID Activo: vs_69679a01bdec8191a9eec55d1cae9f08\n"
     ]
    }
   ],
   "source": [
    "# 2. INGESTI√ìN DE DATOS (Optimizado con Cach√© ‚ö°)\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "# Configuraci√≥n\n",
    "CACHE_FILE = Path(\"vector_store_cache.json\")\n",
    "PDF_PATH = Path(\"../data/raw/TENERIFE.pdf\")\n",
    "\n",
    "# Comprobaci√≥n del PDF (Path Correction)\n",
    "if not PDF_PATH.exists():\n",
    "    if Path(\"data/raw/TENERIFE.pdf\").exists():\n",
    "        PDF_PATH = Path(\"data/raw/TENERIFE.pdf\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No existe el PDF en {PDF_PATH}. Ajusta ruta.\")\n",
    "\n",
    "print(\"PDF:\", PDF_PATH)\n",
    "\n",
    "# 1. Detectar gestor de Vector Stores\n",
    "vs_manager = getattr(client, \"vector_stores\", None) or getattr(getattr(client, \"beta\", None), \"vector_stores\", None)\n",
    "if vs_manager is None:\n",
    "    raise RuntimeError(\"Tu versi√≥n del SDK no expone 'vector_stores'.\")\n",
    "\n",
    "# 2. Intentar recuperar de Cach√©\n",
    "vector_store_id = None\n",
    "if CACHE_FILE.exists():\n",
    "    try:\n",
    "        with open(CACHE_FILE, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            cached_id = data.get(\"vector_store_id\")\n",
    "            # Verificar si sigue vivo en OpenAI\n",
    "            vs_manager.retrieve(cached_id)\n",
    "            vector_store_id = cached_id\n",
    "            print(f\"[CACH√â] ‚ö° ID recuperado y verificado: {vector_store_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[CACH√â] ‚ö†Ô∏è ID inv√°lido o expirado ({e}). Se crear√° uno nuevo.\")\n",
    "\n",
    "# 3. Crear e Ingestar (Solo si no hay cach√©)\n",
    "if not vector_store_id:\n",
    "    print(\"[INGESTA] üê¢ Iniciando proceso de subida (esto tomar√° un momento)...\")\n",
    "    vector_store = vs_manager.create(\n",
    "        name=\"Tenerife_VS_Final\",\n",
    "        chunking_strategy={\"type\": \"static\", \"static\": {\"max_chunk_size_tokens\": 1000, \"chunk_overlap_tokens\": 200}},\n",
    "    )\n",
    "    vector_store_id = vector_store.id\n",
    "    \n",
    "    with open(PDF_PATH, \"rb\") as f:\n",
    "        vs_manager.file_batches.upload_and_poll(\n",
    "            vector_store_id=vector_store_id,\n",
    "            files=[f],\n",
    "        )\n",
    "    \n",
    "    # Guardar nuevo cach√©\n",
    "    with open(CACHE_FILE, \"w\") as f:\n",
    "        json.dump({\"vector_store_id\": vector_store_id}, f)\n",
    "    print(f\"[INGESTA] üíæ Completado y guardado en cach√©: {vector_store_id}\")\n",
    "\n",
    "print(f\"‚úÖ Fase 2 Lista. ID Activo: {vector_store_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fase 3: Configuraci√≥n del Agente RAG ü§ñ\n",
    "Configuramos el agente con capacidad de usar el Vector Store. \n",
    "**Nota**: Incluimos la instalaci√≥n de librer√≠as en el kernel para asegurar que el entorno de ejecuci√≥n tenga todo lo necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Conectando agente al Vector Store: vs_69679a01bdec8191a9eec55d1cae9f08\n",
      "ü§ñ Agente 'TenerifeGuide' configurado satisfactoriamente.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from agents import Agent, Runner, FileSearchTool\n",
    "\n",
    "# Usamos el ID obtenido en Fase 2\n",
    "current_vs_id = vector_store_id\n",
    "print(f\"üîó Conectando agente al Vector Store: {current_vs_id}\")\n",
    "\n",
    "# 1. Definir la herramienta de b√∫squeda de archivos\n",
    "file_search_tool = FileSearchTool(vector_store_ids=[current_vs_id])\n",
    "\n",
    "# 2. Instrucciones del Agente (System Prompt)\n",
    "INSTRUCTIONS = \"\"\"\n",
    "Eres un experto gu√≠a tur√≠stico de Tenerife.\n",
    "Usa la herramienta file_search para encontrar informaci√≥n en la gu√≠a PDF adjunta.\n",
    "Si la informaci√≥n no est√° en el PDF, dilo claramente. No inventes respuestas.\n",
    "Responde siempre en espa√±ol, con un tono amable y entusiasta.\n",
    "\"\"\"\n",
    "\n",
    "# 3. Crear el Agente\n",
    "agent = Agent(\n",
    "    name=\"TenerifeGuide\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[file_search_tool]\n",
    ")\n",
    "\n",
    "print(f\"ü§ñ Agente '{agent.name}' configurado satisfactoriamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba R√°pida del Agente\n",
    "Lanzamos una pregunta de prueba para verificar que el RAG funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ Usuario: ¬øQu√© actividades puedo hacer en el Teide?\n",
      "ü§ñ Agente: ¬°Claro! En el Parque Nacional del Teide puedes disfrutar de diversas actividades que son realmente emocionantes y memorables. Aqu√≠ te dejo algunas sugerencias:\n",
      "\n",
      "1. **Subida al Pico del Teide**: Puedes utilizar los telef√©ricos para ascender hasta el pico del Teide y disfrutar de vistas espectaculares.\n",
      "\n",
      "2. **Observaci√≥n de estrellas**: Si tienes la oportunidad, te recomiendo visitar el Teide por la noche cuando est√© despejado. Es famoso por tener uno de los cielos estrellados m√°s impresionantes del mundo.\n",
      "\n",
      "3. **Senderismo**: Hay numerosas rutas de senderismo que te permiten explorar la belleza natural del parque. Puedes elegir entre diferentes niveles de dificultad dependiendo de tu experiencia y condici√≥n f√≠sica.\n",
      "\n",
      "4. **Centro de Visitantes de El Portillo**: Este centro es gratuito y ofrece informaci√≥n valiosa sobre el parque y su ecosistema, lo que puede enriquecer tu experiencia.\n",
      "\n",
      "¬°No dudes en disfrutar de estas actividades para hacer de tu visita al Teide una experiencia inolvidable! Si necesitas m√°s informaci√≥n, no dudes en preguntar.\n"
     ]
    }
   ],
   "source": [
    "async def demo_agente():\n",
    "    pregunta = \"¬øQu√© actividades puedo hacer en el Teide?\"\n",
    "    print(f\"üë§ Usuario: {pregunta}\")\n",
    "    \n",
    "    # Ejecutamos el agente\n",
    "    resultado = await Runner.run(agent, pregunta)\n",
    "    print(f\"ü§ñ Agente: {resultado.final_output}\")\n",
    "\n",
    "await demo_agente()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. FASE 4: GENERACI√ìN DE DATASET DE EVALUACI√ìN\n",
    "\n",
    "Para medir la calidad de nuestro RAG, necesitamos un \"Gold Standard\" o dataset de prueba.\n",
    "En lugar de escribirlo a mano, usaremos un **Agente Auxiliar ('DatasetBuilder')**.\n",
    "\n",
    "Este agente leer√° el PDF y generar√° pares de Pregunta/Respuesta con referencias exactas.\n",
    "Esto asegura que las pruebas est√©n alineadas con el contenido real del documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agente DatasetBuilder configurado.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "# Modelo de datos para cada item de evaluaci√≥n\n",
    "class EvalItem(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "    references: List[str]\n",
    "\n",
    "NUM_EXAMPLES = 5  # N√∫mero de pares a generar (puedes aumentar esto luego)\n",
    "MODEL_GENERATOR = \"gpt-4o-mini\" # Usamos el mismo modelo capaz\n",
    "\n",
    "# Definici√≥n del Agente Generador\n",
    "dataset_agent = Agent(\n",
    "    name=\"DatasetBuilder\",\n",
    "    model=MODEL_GENERATOR,\n",
    "    instructions=(\n",
    "        \"Eres un generador de datasets de QA (Pregunta/Respuesta) basado en un PDF accesible v√≠a file_search. \"\n",
    "        \"Crea preguntas variadas (literales, s√≠ntesis, curiosidades) sobre Tenerife y respuestas concisas apoyadas en el texto. \"\n",
    "        \"Debes devolver un JSON con una lista de objetos que sigan la estructura {question, answer, references}. \"\n",
    "        \"Las 'references' deben ser citas textuales exactas del PDF que soporten la respuesta. NO inventes texto.\"\n",
    "    ),\n",
    "    tools=[file_search_tool], # Reutilizamos la tool configurada en Fase 3\n",
    "    output_type=List[EvalItem],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente DatasetBuilder configurado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Generando 5 ejemplos de evaluaci√≥n... (Esto puede tardar unos segundos)\n",
      "\n",
      "‚úÖ Generados 5 ejemplos:\n",
      "[1] P: ¬øCu√°l es el clima de Tenerife?\n",
      "    R: El clima de Tenerife es generalmente c√°lido y templado durante todo el a√±o....\n",
      "[2] P: ¬øQu√© actividades al aire libre se pueden realizar en Tenerife?\n",
      "    R: En Tenerife se pueden realizar diversas actividades al aire libre como excursiones en kayak, motos d...\n",
      "[3] P: ¬øCu√°les son los principales atractivos tur√≠sticos de Tenerife?\n",
      "    R: Los principales atractivos tur√≠sticos incluyen el Teide, Siam Park, el Loro Parque y los Acantilados...\n",
      "[4] P: ¬øQu√© caracter√≠sticas geogr√°ficas tiene Tenerife?\n",
      "    R: Tenerife es una isla volc√°nica que presenta un paisaje monta√±oso, siendo el Teide su pico m√°s alto y...\n",
      "[5] P: ¬øCu√°l es la gastronom√≠a t√≠pica de Tenerife?\n",
      "    R: La gastronom√≠a t√≠pica incluye platos como el mojo, las papas arrugadas y experiencias en guachinches...\n"
     ]
    }
   ],
   "source": [
    "# Prompt para disparar la generaci√≥n\n",
    "dataset_prompt = (\n",
    "    f\"Genera {NUM_EXAMPLES} pares de pregunta/respuesta basados √∫nicamente en el PDF de Tenerife. \"\n",
    "    \"Incluye las referencias textuales relevantes en el campo 'references'. \"\n",
    "    \"Responde solo con un JSON v√°lido.\"\n",
    ")\n",
    "\n",
    "print(f\"‚è≥ Generando {NUM_EXAMPLES} ejemplos de evaluaci√≥n... (Esto puede tardar unos segundos)\")\n",
    "\n",
    "try:\n",
    "    # Ejecuci√≥n del agente\n",
    "    dataset_result = await Runner.run(dataset_agent, dataset_prompt)\n",
    "    \n",
    "    # Extracci√≥n del resultado tipado\n",
    "    eval_dataset = dataset_result.final_output_as(List[EvalItem])\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generados {len(eval_dataset)} ejemplos:\")\n",
    "    for i, item in enumerate(eval_dataset, 1):\n",
    "        print(f\"[{i}] P: {item.question}\")\n",
    "        print(f\"    R: {item.answer[:100]}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error generando dataset: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Dataset guardado en: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-tarea-final\\notebooks\\eval_dataset_tenerife.json\n"
     ]
    }
   ],
   "source": [
    "# Guardar el dataset en disco para no regenerarlo siempre\n",
    "DATASET_PATH = Path(\"eval_dataset_tenerife.json\")\n",
    "\n",
    "if 'eval_dataset' in locals() and eval_dataset:\n",
    "    with open(DATASET_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump([item.model_dump() for item in eval_dataset], f, ensure_ascii=False, indent=2)\n",
    "    print(f\"üíæ Dataset guardado en: {DATASET_PATH.absolute()}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay dataset para guardar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. FASE 5: VERIFICACI√ìN Y M√âTRICAS (JUEZ LLM)\n",
    "\n",
    "Ya tenemos Agente y Dataset. Ahora necesitamos saber **qu√© tan bien** funciona.\n",
    "Usaremos un segundo LLM (Juez) para calificar cada respuesta del Agente seg√∫n:\n",
    "1.  **Faithfulness (Fidelidad):** ¬øSe invent√≥ algo?\n",
    "2.  **Answer Correctness:** ¬øCoincide con la respuesta esperada?\n",
    "3.  **Context Precision:** ¬øLos trozos de PDF recuperados eran √∫tiles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agente Juez configurado.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import statistics\n",
    "from typing import Dict, Any, List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Aseguramos imports\n",
    "from agents import Agent, Runner\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Definici√≥n de la Salida del Juez\n",
    "class JudgeScores(BaseModel):\n",
    "    faithfulness: float\n",
    "    answer_correctness: float\n",
    "    context_precision: float\n",
    "    reasoning: str\n",
    "\n",
    "# Definici√≥n del Juez (usamos gpt-4o-mini por ser r√°pido y capaz)\n",
    "judge_agent = Agent(\n",
    "    name=\"EvalJudge\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=(\n",
    "        \"Act√∫as como un juez evaluador de sistemas RAG. \"\n",
    "        \"Debes generar puntuaciones (0.0 a 1.0) para: \"\n",
    "        \"1. Faithfulness: ¬øLa respuesta se basa solo en el contexto recuperado? (1=S√≠, 0=Alucinaci√≥n total). \"\n",
    "        \"2. Answer Correctness: ¬øLa respuesta del agente coincide sem√°nticamente con la respuesta de referencia? \"\n",
    "        \"3. Context Precision: ¬øLos contextos recuperados son relevantes para la pregunta? \"\n",
    "        \"Devuelve un JSON con los campos num√©ricos y un breve 'reasoning'.\"\n",
    "    ),\n",
    "    output_type=JudgeScores\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente Juez configurado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n auxiliar para extraer el texto de los contextos recuperados\n",
    "def extract_contexts(run_result) -> List[str]:\n",
    "    contexts = []\n",
    "    # Inspeccionamos items generados buscando llamadas a tools\n",
    "    if hasattr(run_result, 'new_items'):\n",
    "        for item in run_result.new_items:\n",
    "            raw = getattr(item, \"raw_item\", None)\n",
    "            # Detectar llamada a file_search\n",
    "            if getattr(raw, \"type\", None) == \"file_search_call\":\n",
    "                for res in getattr(raw, \"results\", []) or []:\n",
    "                    text = getattr(res, \"text\", None) or getattr(res, \"content\", None)\n",
    "                    if text: contexts.append(text)\n",
    "    return contexts\n",
    "\n",
    "# Funci√≥n que eval√∫a UNA sola pregunta\n",
    "async def evaluate_example(agent_to_test: Agent, example: EvalItem):\n",
    "    # 1. El Agente a testear responde la pregunta\n",
    "    run_res = await Runner.run(agent_to_test, example.question)\n",
    "    agent_answer = run_res.final_output\n",
    "    contexts = extract_contexts(run_res)\n",
    "    \n",
    "    # 2. El Juez eval√∫a la calidad\n",
    "    context_text = \"\\n---\\n\".join(contexts[:3]) # Top 3 contextos\n",
    "    judge_prompt = (\n",
    "        f\"Pregunta: {example.question}\\n\"\n",
    "        f\"Respuesta Agente: {agent_answer}\\n\"\n",
    "        f\"Respuesta Referencia: {example.answer}\\n\"\n",
    "        f\"Contextos Recuperados: {context_text}\\n\"\n",
    "        \"Eval√∫a con rigor.\"\n",
    "    )\n",
    "    \n",
    "    judge_res = await Runner.run(judge_agent, judge_prompt)\n",
    "    scores = judge_res.final_output_as(JudgeScores)\n",
    "    \n",
    "    return {\n",
    "        \"question\": example.question,\n",
    "        \"agent_answer\": agent_answer,\n",
    "        \"reference\": example.answer,\n",
    "        \"faithfulness\": scores.faithfulness,\n",
    "        \"correctness\": scores.answer_correctness,\n",
    "        \"ctx_precision\": scores.context_precision,\n",
    "        \"reasoning\": scores.reasoning\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Evaluando los 5 ejemplos con el Juez... Estiman 10-20 segundos.\n",
      ". Completado: ¬øCu√°l es el clima de Tenerife?... -> F:0.9 C:0.8\n",
      ". Completado: ¬øQu√© actividades al aire libre... -> F:1.0 C:0.7\n",
      ". Completado: ¬øCu√°les son los principales at... -> F:1.0 C:0.75\n",
      ". Completado: ¬øQu√© caracter√≠sticas geogr√°fic... -> F:1.0 C:0.8\n",
      ". Completado: ¬øCu√°l es la gastronom√≠a t√≠pica... -> F:1.0 C:0.9\n",
      "\n",
      "‚úÖ Evaluaci√≥n Finalizada.\n"
     ]
    }
   ],
   "source": [
    "# Ejecuci√≥n Masiva de la Evaluaci√≥n\n",
    "print(f\"‚è≥ Evaluando los {len(eval_dataset)} ejemplos con el Juez... Estiman 10-20 segundos.\")\n",
    "\n",
    "results = []\n",
    "for ex in eval_dataset:\n",
    "    res = await evaluate_example(agent, ex)\n",
    "    results.append(res)\n",
    "    # Peque√±o print de progreso\n",
    "    print(f\". Completado: {ex.question[:30]}... -> F:{res['faithfulness']} C:{res['correctness']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Evaluaci√≥n Finalizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Promedios Generales:\n",
      "üíæ Resultados guardados en 'eval_results.csv'\n",
      "faithfulness     0.98\n",
      "correctness      0.79\n",
      "ctx_precision    0.96\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>agent_answer</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>correctness</th>\n",
       "      <th>ctx_precision</th>\n",
       "      <th>reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>¬øCu√°l es el clima de Tenerife?</td>\n",
       "      <td>¬°Claro! El clima de Tenerife es conocido por s...</td>\n",
       "      <td>El clima de Tenerife es generalmente c√°lido y ...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.9</td>\n",
       "      <td>La respuesta del agente presenta informaci√≥n d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¬øQu√© actividades al aire libre se pueden reali...</td>\n",
       "      <td>¬°Tenerife es un para√≠so para las actividades a...</td>\n",
       "      <td>En Tenerife se pueden realizar diversas activi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.9</td>\n",
       "      <td>La respuesta del agente est√° completamente bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¬øCu√°les son los principales atractivos tur√≠sti...</td>\n",
       "      <td>¬°Tenerife es un destino incre√≠ble con una vari...</td>\n",
       "      <td>Los principales atractivos tur√≠sticos incluyen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>La respuesta del agente est√° basada completame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>¬øQu√© caracter√≠sticas geogr√°ficas tiene Tenerife?</td>\n",
       "      <td>Tenerife es una isla fascinante con una geogra...</td>\n",
       "      <td>Tenerife es una isla volc√°nica que presenta un...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>La respuesta del agente se basa en el contexto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>¬øCu√°l es la gastronom√≠a t√≠pica de Tenerife?</td>\n",
       "      <td>La gastronom√≠a t√≠pica de Tenerife es deliciosa...</td>\n",
       "      <td>La gastronom√≠a t√≠pica incluye platos como el m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>La respuesta del agente se basa completamente ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                     ¬øCu√°l es el clima de Tenerife?   \n",
       "1  ¬øQu√© actividades al aire libre se pueden reali...   \n",
       "2  ¬øCu√°les son los principales atractivos tur√≠sti...   \n",
       "3   ¬øQu√© caracter√≠sticas geogr√°ficas tiene Tenerife?   \n",
       "4        ¬øCu√°l es la gastronom√≠a t√≠pica de Tenerife?   \n",
       "\n",
       "                                        agent_answer  \\\n",
       "0  ¬°Claro! El clima de Tenerife es conocido por s...   \n",
       "1  ¬°Tenerife es un para√≠so para las actividades a...   \n",
       "2  ¬°Tenerife es un destino incre√≠ble con una vari...   \n",
       "3  Tenerife es una isla fascinante con una geogra...   \n",
       "4  La gastronom√≠a t√≠pica de Tenerife es deliciosa...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0  El clima de Tenerife es generalmente c√°lido y ...           0.9   \n",
       "1  En Tenerife se pueden realizar diversas activi...           1.0   \n",
       "2  Los principales atractivos tur√≠sticos incluyen...           1.0   \n",
       "3  Tenerife es una isla volc√°nica que presenta un...           1.0   \n",
       "4  La gastronom√≠a t√≠pica incluye platos como el m...           1.0   \n",
       "\n",
       "   correctness  ctx_precision  \\\n",
       "0         0.80            0.9   \n",
       "1         0.70            0.9   \n",
       "2         0.75            1.0   \n",
       "3         0.80            1.0   \n",
       "4         0.90            1.0   \n",
       "\n",
       "                                           reasoning  \n",
       "0  La respuesta del agente presenta informaci√≥n d...  \n",
       "1  La respuesta del agente est√° completamente bas...  \n",
       "2  La respuesta del agente est√° basada completame...  \n",
       "3  La respuesta del agente se basa en el contexto...  \n",
       "4  La respuesta del agente se basa completamente ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reporte de Resultados\n",
    "try:\n",
    "    import pandas as pd\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(\"\\nPromedios Generales:\")\n",
    "    df_results.to_csv(\"eval_results.csv\", index=False, encoding='utf-8')\n",
    "    print(\"üíæ Resultados guardados en 'eval_results.csv'\")\n",
    "    print(df_results[[\"faithfulness\", \"correctness\", \"ctx_precision\"]].mean())\n",
    "    display(df_results) # Pretty print en notebook\n",
    "except ImportError:\n",
    "    # Fallback si no hay pandas\n",
    "    print(\"\\nResultados Detallados:\")\n",
    "    for r in results:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. FASE 6: FUNCTION CALLING (CLIMA)\n",
    "\n",
    "Implementamos una herramienta externa (`get_weather`) usando el decorador `@function_tool`.\n",
    "Esto permite al Agente invocar c√≥digo Python real (o simulado) para obtener estructuras JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agente 'TenerifeGuidePro' configurado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import datetime\n",
    "import json\n",
    "from agents import function_tool  # Importante: Decorador para herramientas\n",
    "\n",
    "# 1. Definimos la funci√≥n decorada\n",
    "@function_tool\n",
    "def get_weather(location: str, date: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Obtiene la previsi√≥n del tiempo para una ubicaci√≥n y fecha dadas.\n",
    "    \n",
    "    Args:\n",
    "        location: Ciudad o lugar (ej: 'Tenerife').\n",
    "        date: Fecha en formato YYYY-MM-DD o 'hoy'.\n",
    "    \"\"\"\n",
    "    # Log solicitado por requisitos\n",
    "    print(f\"[TOOL LOG] Llamada a get_weather(location='{location}', date='{date}')\")\n",
    "    \n",
    "    # Mock (Simulaci√≥n)\n",
    "    if not date:\n",
    "        date = datetime.date.today().isoformat()\n",
    "    \n",
    "    climates = [\"Soleado\", \"Parcialmente nublado\", \"Viento moderado\"]\n",
    "    temp = random.randint(20, 28)\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"location\": location,\n",
    "        \"date\": date,\n",
    "        \"condition\": random.choice(climates),\n",
    "        \"temperature\": f\"{temp}¬∫C\",\n",
    "        \"note\": \"Simulaci√≥n acad√©mica\"\n",
    "    })\n",
    "\n",
    "# 2. Creamos el Agente con la herramienta correctamente configurada\n",
    "weather_agent = Agent(\n",
    "    name=\"TenerifeGuidePro\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=(\n",
    "        \"Eres el experto tur√≠stico definitivo de Tenerife. \"\n",
    "        \"Usa file_search para responder dudas sobre lugares bas√°ndote en el PDF. \"\n",
    "        \"Usa get_weather si el usuario pregunta por el tiempo o clima actual. \"\n",
    "        \"Combina ambas fuentes para dar consejos complejos.\"\n",
    "    ),\n",
    "    tools=[file_search_tool, get_weather]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente 'TenerifeGuidePro' configurado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ Usuario: ¬øQu√© tiempo hace hoy en el Teide y qu√© me recomiendas hacer all√≠ seg√∫n el PDF?\n",
      "‚è≥ Pensando...\n",
      "[TOOL LOG] Llamada a get_weather(location='Teide', date='hoy')\n",
      "ü§ñ Agente: Hoy en el Teide, el clima es de 21¬∞C con viento moderado. Aqu√≠ tienes algunas recomendaciones de actividades que puedes realizar all√≠:\n",
      "\n",
      "1. **Subida al Pico del Teide**: Puedes usar los telef√©ricos para subir al pico. Es una experiencia incre√≠ble y si te gusta el senderismo, hay rutas que puedes tomar para explorar m√°s la zona.\n",
      "\n",
      "2. **Centro de Visitantes de El Portillo**: Este centro ofrece informaci√≥n sobre el Parque Nacional y es gratuito. Es un buen lugar para aprender sobre la fauna y flora de la zona.\n",
      "\n",
      "3. **Miradores**: A lo largo del camino hacia el Teide, puedes hacer paradas en miradores como el de La Tarta, que ofrece vistas espectaculares y, si tienes suerte, un mar de nubes en el norte.\n",
      "\n",
      "4. **Noche de Estrellas**: Si el clima es favorable, considera quedarte para ver el cielo estrellado, que es uno de los m√°s impresionantes del mundo. Los cielos despejados hacen que la experiencia sea a√∫n mejor.\n",
      "\n",
      "Aseg√∫rate de llevar suficiente agua y algo de abrigo, ya que la temperatura puede bajar al anochecer. ¬°Disfruta de tu visita al Teide!\n"
     ]
    }
   ],
   "source": [
    "# Prueba de Function Calling + RAG\n",
    "pregunta_clima = \"¬øQu√© tiempo hace hoy en el Teide y qu√© me recomiendas hacer all√≠ seg√∫n el PDF?\"\n",
    "\n",
    "print(f\"üë§ Usuario: {pregunta_clima}\")\n",
    "print(\"‚è≥ Pensando...\")\n",
    "\n",
    "try:\n",
    "    resultado_completo = await Runner.run(weather_agent, pregunta_clima)\n",
    "    print(f\"ü§ñ Agente: {resultado_completo.final_output}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. FASE 7: AN√ÅLISIS FINAL Y CONCLUSIONES üìä\n",
    "\n",
    "En esta √∫ltima fase, nuestro objetivo es sintetizar todo lo aprendido. No basta con ver n√∫meros en una tabla; queremos que el propio LLM (actuando como Analista) revise los resultados de la evaluaci√≥n (Fase 5) y nos d√© un informe ejecutivo.\n",
    "\n",
    "Esto cierra el ciclo: **Ingesta -> RAG -> Evaluaci√≥n -> Mejora Continua**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Generando An√°lisis Final del Proyecto...\n",
      "‚ö†Ô∏è Error obteniendo m√©tricas: cannot access local variable 'df_results' where it is not associated with a value\n"
     ]
    }
   ],
   "source": [
    "async def generar_informe_final():\n",
    "    print(\"üìä Generando An√°lisis Final del Proyecto...\")\n",
    "    \n",
    "    # 1. Recuperaci√≥n de Datos (Memoria o Disco)\n",
    "    stats_md = \"\"\n",
    "    try:\n",
    "        if 'df_results' not in globals():\n",
    "            import pandas as pd\n",
    "            if os.path.exists(\"eval_results.csv\"):\n",
    "                print(\"[INFO] Cargando resultados desde archivo CSV...\")\n",
    "                df_results = pd.read_csv(\"eval_results.csv\")\n",
    "            else:\n",
    "                raise FileNotFoundError(\"No se encontraron resultados en memoria ni en 'eval_results.csv'. Ejecuta la Fase 5.\")\n",
    "        \n",
    "        # Calcular estad√≠sticas\n",
    "        stats = df_results[[\"faithfulness\", \"correctness\", \"ctx_precision\"]].describe()\n",
    "        stats_md = stats.to_markdown()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error obteniendo m√©tricas: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 2. Agente Analista\n",
    "    analyst_agent = Agent(\n",
    "        name=\"ProjectAnalyst\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        instructions=(\n",
    "            \"Eres un Analista Senior. Analiza las m√©tricas de evaluaci√≥n RAG proporcionadas. \"\n",
    "            \"Redacta un informe ejecutivo breve (m√°x 5 l√≠neas) con: \"\n",
    "            \"1. Resumen de rendimiento (¬øEs fiable?). \"\n",
    "            \"2. Veredicto final. \"\n",
    "            \"S√© directo y profesional.\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    prompt_analisis = (\n",
    "        f\"Analiza estas m√©tricas:\\n{stats_md}\\n\\n\"\n",
    "        \"Genera el informe final ahora.\"\n",
    "    )\n",
    "    \n",
    "    informe = await Runner.run(analyst_agent, prompt_analisis)\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"üìë INFORME FINAL DEL PROYECTO\")\n",
    "    print(\"=\"*40 + \"\\n\")\n",
    "    print(informe.final_output)\n",
    "\n",
    "# Ejecutar an√°lisis\n",
    "await generar_informe_final()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin de la Demostraci√≥n\n",
    "¬°Felicidades! Has completado el ciclo de vida completo de una aplicaci√≥n LLM profesional."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
